/**
 * Pinecone Assistant Data Plane API
 * Pinecone Assistant Engine is a context engine to store and retrieve relevant knowledge from millions of documents at scale. This API supports interactions with assistants.
 *
 * The version of the OpenAPI document: 2025-04
 * Contact: support@pinecone.io
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
/**
 * Controls the context snippets sent to the LLM.
 * @export
 * @interface ContextOptionsModel
 */
export interface ContextOptionsModel {
    /**
     * The maximum number of context snippets to use. Default is 16. Maximum is 64.
     * @type {number}
     * @memberof ContextOptionsModel
     */
    topK?: number;
    /**
     * The maximum context snippet size. Default is 2048 tokens. Minimum is 512 tokens. Maximum is 8192 tokens.
     * @type {number}
     * @memberof ContextOptionsModel
     */
    snippetSize?: number;
}
/**
 * Check if a given object implements the ContextOptionsModel interface.
 */
export declare function instanceOfContextOptionsModel(value: object): boolean;
export declare function ContextOptionsModelFromJSON(json: any): ContextOptionsModel;
export declare function ContextOptionsModelFromJSONTyped(json: any, ignoreDiscriminator: boolean): ContextOptionsModel;
export declare function ContextOptionsModelToJSON(value?: ContextOptionsModel | null): any;
