/**
 * Pinecone Assistant Data Plane API
 * Pinecone Assistant Engine is a context engine to store and retrieve relevant knowledge from millions of documents at scale. This API supports interactions with assistants.
 *
 * The version of the OpenAPI document: 2025-04
 * Contact: support@pinecone.io
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
import type { ContextOptionsModel } from './ContextOptionsModel';
import type { MessageModel } from './MessageModel';
/**
 * The list of queries / chats to chat an assistant
 * @export
 * @interface Chat
 */
export interface Chat {
    /**
     *
     * @type {Array<MessageModel>}
     * @memberof Chat
     */
    messages: Array<MessageModel>;
    /**
     * If false, the assistant will return a single JSON response. If true, the assistant will return a stream of responses.
     * @type {boolean}
     * @memberof Chat
     */
    stream?: boolean;
    /**
     * The large language model to use for answer generation
     * @type {string}
     * @memberof Chat
     */
    model?: ChatModelEnum;
    /**
     * Controls the randomness of the model's output: lower values make responses more deterministic, while higher values increase creativity and variability. If the model does not support a temperature parameter, the parameter will be ignored.
     * @type {number}
     * @memberof Chat
     */
    temperature?: number;
    /**
     * Optionally filter which documents can be retrieved using the following metadata fields.
     * @type {object}
     * @memberof Chat
     */
    filter?: object;
    /**
     * If true, the assistant will be instructed to return a JSON response. Cannot be used with streaming.
     * @type {boolean}
     * @memberof Chat
     */
    jsonResponse?: boolean;
    /**
     * If true, the assistant will be instructed to return highlights from the referenced documents that support its response.
     * @type {boolean}
     * @memberof Chat
     */
    includeHighlights?: boolean;
    /**
     *
     * @type {ContextOptionsModel}
     * @memberof Chat
     */
    contextOptions?: ContextOptionsModel;
}
/**
 * @export
 */
export declare const ChatModelEnum: {
    readonly Gpt4o: "gpt-4o";
    readonly Gpt41: "gpt-4.1";
    readonly O4Mini: "o4-mini";
    readonly Claude35Sonnet: "claude-3-5-sonnet";
    readonly Claude37Sonnet: "claude-3-7-sonnet";
    readonly Gemini25Pro: "gemini-2.5-pro";
};
export type ChatModelEnum = typeof ChatModelEnum[keyof typeof ChatModelEnum];
/**
 * Check if a given object implements the Chat interface.
 */
export declare function instanceOfChat(value: object): boolean;
export declare function ChatFromJSON(json: any): Chat;
export declare function ChatFromJSONTyped(json: any, ignoreDiscriminator: boolean): Chat;
export declare function ChatToJSON(value?: Chat | null): any;
