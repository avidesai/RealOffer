/**
 * Evaluation API
 * Provides endpoints for evaluating RAG systems using various metrics.
 *
 * The version of the OpenAPI document: 2025-04
 * Contact: support@pinecone.io
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
import * as runtime from '../runtime';
import type { AlignmentRequest, AlignmentResponse } from '../models/index';
export interface MetricsAlignmentRequest {
    alignmentRequest: AlignmentRequest;
}
/**
 *
 */
export declare class MetricsApi extends runtime.BaseAPI {
    /**
     * Evaluate the correctness and completeness of a response from an assistant or a RAG system. The correctness and completeness are evaluated based on the precision and recall of the generated answer with respect to the ground truth answer facts. Alignment is the harmonic mean of correctness and completeness.  For guidance and examples, see [Evaluate answers](https://docs.pinecone.io/guides/assistant/evaluate-answers).
     * Evaluate an answer
     */
    metricsAlignmentRaw(requestParameters: MetricsAlignmentRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<AlignmentResponse>>;
    /**
     * Evaluate the correctness and completeness of a response from an assistant or a RAG system. The correctness and completeness are evaluated based on the precision and recall of the generated answer with respect to the ground truth answer facts. Alignment is the harmonic mean of correctness and completeness.  For guidance and examples, see [Evaluate answers](https://docs.pinecone.io/guides/assistant/evaluate-answers).
     * Evaluate an answer
     */
    metricsAlignment(requestParameters: MetricsAlignmentRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<AlignmentResponse>;
}
