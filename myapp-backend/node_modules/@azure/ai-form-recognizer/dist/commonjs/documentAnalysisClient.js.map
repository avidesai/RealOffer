{"version":3,"file":"documentAnalysisClient.js","sourceRoot":"","sources":["../../src/documentAnalysisClient.ts"],"names":[],"mappings":";AAAA,uCAAuC;AACvC,kCAAkC;;;AAGlC,sDAA0D;AAE1D,iDAA0E;AAM1E,oEAA2D;AAQ3D,mDAG2B;AAE3B,oDAA2C;AAI3C,uCAAmE;AAInE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA+BG;AACH,MAAa,sBAAsB;IAgEjC,YACE,QAAgB,EAChB,UAA2C,EAC3C,UAAyC,EAAE;QAE3C,IAAI,CAAC,WAAW,GAAG,IAAA,2BAAiB,EAAC,QAAQ,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC;QACpE,IAAI,CAAC,QAAQ,GAAG,IAAA,kCAAmB,EAAC;YAClC,WAAW,EAAE,2BAA2B;YACxC,cAAc,EAAE,0BAAW;YAC3B,SAAS,EAAE,6BAA6B;SACzC,CAAC,CAAC;IACL,CAAC;IA2JM,KAAK,CAAC,oBAAoB,CAC/B,KAAsC,EACtC,QAAmC;IACnC,8DAA8D;IAC9D,UAA2C,EAAE;QAE7C,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,6CAA6C,EAC7C,OAAO;QACP,+GAA+G;QAC/G,wDAAwD;QACxD,IAAI,CAAC,OAAO,CAAC,IAAI,CACf,IAAI,EACJ,KAAK,EACL,OAAO,QAAQ,KAAK,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,EAAE,QAAQ,CAAC,CAClF,CACF,CAAC;IACJ,CAAC;IA4IM,KAAK,CAAC,2BAA2B,CACtC,KAAsC,EACtC,WAAmB;IACnB,8DAA8D;IAC9D,UAA2C,EAAE;QAE7C,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,oDAAoD,EACpD,OAAO,EACP,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC,CAC3D,CAAC;IACJ,CAAC;IAED;;;;;;;OAOG;IACK,OAAO,CACb,KAAsC,EACtC,KAAqB,EACrB,OAAwC;QAExC,MAAM,EACJ,OAAO,EAAE,cAAc,EACvB,UAAU,EAAE,iBAAiB,EAC7B,eAAe,GAChB,GAAG,OAAO,KAAK,KAAK,QAAQ;YAC3B,CAAC,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,UAAU,EAAE,SAAS,EAAE,eAAe,EAAE,CAAC,CAAgB,EAAE,EAAE,CAAC,CAAC,EAAE;YACrF,CAAC,CAAC,KAAK,CAAC;QAEV,IAAI,iBAAiB,IAAI,iBAAiB,KAAK,0CAA2B,EAAE,CAAC;YAC3E,MAAM,IAAI,KAAK,CACb;gBACE,2DAA2D,iBAAiB,GAAG;gBAC/E,2BAA2B,0CAA2B,GAAG;gBACzD,mEAAmE;aACpE,CAAC,IAAI,CAAC,GAAG,CAAC,CACZ,CAAC;QACJ,CAAC;QAED,OAAO,IAAI,CAAC,mBAAmB,CAC7B,CAAC,WAAW,EAAE,EAAE;YACd,MAAM,CAAC,WAAW,EAAE,cAAc,CAAC,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC;YAE9D,IAAI,WAAW,KAAK,kBAAkB,EAAE,CAAC;gBACvC,OAAO,IAAI,CAAC,WAAW,CAAC,cAAc,CAAC,eAAe,CAAC,cAAc,EAAE,WAAW,kCAC7E,OAAO,KACV,WAAW;oBACX,cAAc,IACd,CAAC;YACL,CAAC;iBAAM,CAAC;gBACN,OAAO,IAAI,CAAC,WAAW,CAAC,cAAc,CAAC,eAAe,CAAC,cAAc,EAAE,WAAW,kCAC7E,OAAO,KACV,WAAW;oBACX,cAAc,IACd,CAAC;YACL,CAAC;QACH,CAAC,EACD;YACE,cAAc;YACd,OAAO;YACP,eAAe,EAAE,CAAC,MAAM,EAAE,EAAE,CAAC,eAAe,CAAC,IAAA,0CAA4B,EAAC,MAAM,CAAC,CAAC;SACnF,CACF,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OA+CG;IACI,KAAK,CAAC,qBAAqB,CAChC,YAAoB,EACpB,QAAmC;IACnC,8DAA8D;IAC9D,UAAmC,EAAE;QAErC,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,8CAA8C,EAC9C,OAAO,EACP,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,EAAE,YAAY,EAAE,MAAM,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC,CACjE,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OA+CG;IACI,KAAK,CAAC,4BAA4B,CACvC,YAAoB,EACpB,WAAmB;IACnB,8DAA8D;IAC9D,UAAmC,EAAE;QAErC,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,qDAAqD,EACrD,OAAO,EACP,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,EAAE,YAAY,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC,CACnE,CAAC;IACJ,CAAC;IAED;;;;;;OAMG;IACK,QAAQ,CACd,YAAoB,EACpB,KAAqB,EACrB,OAAgC;QAEhC,OAAO,IAAI,CAAC,mBAAmB,CAC7B,KAAK,EAAE,WAAW,EAAE,EAAE;YACpB,MAAM,CAAC,WAAW,EAAE,eAAe,CAAC,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC;YAE/D,IAAI,WAAW,KAAK,kBAAkB,EAAE,CAAC;gBACvC,OAAO,IAAI,CAAC,WAAW,CAAC,mBAAmB,CAAC,gBAAgB,CAC1D,YAAY,EACZ,WAAkB,kCAEb,OAAO,KACV,WAAW;oBACX,eAAe,IAElB,CAAC;YACJ,CAAC;iBAAM,CAAC;gBACN,OAAO,IAAI,CAAC,WAAW,CAAC,mBAAmB,CAAC,gBAAgB,CAC1D,YAAY,EACZ,WAAkB,kCAEb,OAAO,KACV,WAAW;oBACX,eAAe,IAElB,CAAC;YACJ,CAAC;QACH,CAAC,EACD;YACE,cAAc,EAAE,YAAY;YAC5B,OAAO;YACP,eAAe,EAAE,0CAA4B;SAC9C,CACF,CAAC;IACJ,CAAC;IAED;;;;;;;;OAQG;IACK,KAAK,CAAC,mBAAmB,CAC/B,cAE4C,EAC5C,UAA+C;QAE/C,MAAM,EAAE,UAAU,EAAE,GAAG,UAAU,CAAC,OAAO,CAAC;QAE1C,kFAAkF;QAClF,+CAA+C;QAE/C,MAAM,gBAAgB,GAAG,CACvB,GAAqB,EACrB,iBAAyB,EACQ,EAAE,CACnC,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,8DAA8D,EAC9D,UAAU,CAAC,OAAO,EAClB,CAAC,YAAY,EAAE,EAAE,CACf,IAAI,CAAC,WAAW,CAAC,oBAAoB,CACnC;YACE,OAAO,gCACL,UAAU,EAAE,KAAK,EAAE,WAAW,EAAE,GAAG,IAAI,EAAE,EAAE;;oBACzC,mDAAmD;oBACnD,MAAM,gBAAgB,GAAG,WAAW,CAAC,OAAO,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC;oBAChE,oGAAoG;oBACpG,QAAQ;oBACR,IAAI,gBAAgB,EAAE,CAAC;wBACrB,MAAM,YAAY,GAAG,MAAM,CAAC,gBAAgB,CAAC,GAAG,IAAI,CAAC;wBACrD,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,EAAE,CAAC;4BAChC,GAAG,CAAC,WAAW,CAAC,YAAY,CAAC,CAAC;wBAChC,CAAC;6BAAM,CAAC;4BACN,GAAG,CAAC,WAAW,CAAC,IAAI,CAAC,KAAK,CAAC,gBAAgB,CAAC,GAAG,IAAI,CAAC,GAAG,EAAE,CAAC,CAAC;wBAC7D,CAAC;oBACH,CAAC;yBAAM,CAAC;wBACN,GAAG,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;oBAC7B,CAAC;oBAED,wDAAwD;oBACxD,OAAO,MAAA,YAAY,CAAC,UAAU,6DAAG,WAAW,EAAE,GAAG,IAAI,CAAC,CAAC;gBACzD,CAAC,IACE,YAAY;gBACf,uGAAuG;gBACvG,2EAA2E;gBAC3E,WAAW,EAAE,GAAG,CAAC,WAAW,GAC7B;SACF,EACD;YACE,IAAI,EAAE,iBAAiB;YACvB,UAAU,EAAE,KAAK;YACjB,SAAS,EAAE;gBACT,GAAG,EAAE;oBACH,UAAU,EAAE,iBAAO,CAAC,sBAAsB;iBAC3C;gBACD,OAAO,EAAE;oBACP,UAAU,EAAE,iBAAO,CAAC,aAAa;iBAClC;aACF;YACD,6DAA6D;YAC7D,gBAAgB,EAAE,CAAC,uBAAO,CAAC;YAC3B,UAAU,EAAE,oBAAU;SACvB,CACF,CACJ,CAAC;QAEJ,MAAM,MAAM;QACV,0DAA0D;QAC1D,UAAU,KAAK,SAAS;YACtB,CAAC,CAAC,KAAK,EAAE,GAAqB,EAAE,EAAE,CAC9B,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,oDAAoD,EACpD,UAAU,CAAC,OAAO,EAClB,KAAK,IAAI,EAAE;gBACT,MAAM,EAAE,aAAa,EAAE,iBAAiB,EAAE,OAAO,EAAE,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAI1E,CAAC;gBAEF,IAAI,CAAC,aAAa,IAAI,aAAa,KAAK,0BAAW,EAAE,CAAC;oBACpD,MAAM,IAAI,KAAK,CACb;wBACE,sFAAsF;wBACtF,0BAA0B,aAAa,gBAAgB,0BAAW,KAAK;qBACxE,CAAC,IAAI,CAAC,GAAG,CAAC,CACZ,CAAC;gBACJ,CAAC;gBAED,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,GAAG,EAAE,iBAAiB,CAAC,CAAC;gBAE9D,OAAO,IAAA,kDAAoC,EACzC,UAAU,EACV,OAAO,EACP,iBAAiB,EACjB,MAAM,CACP,CAAC;YACJ,CAAC,CACF;YACL,CAAC,CAAC,iEAAiE;gBACjE,KAAK,EAAE,GAAqB,EAAE,EAAE,CAC9B,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,mDAAmD,EACnD,UAAU,CAAC,OAAO,EAClB,KAAK,IAAI,EAAE;oBACT,MAAM,EAAE,iBAAiB,EAAE,GAAG,MAAM,cAAc,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;oBAEpE,IAAI,iBAAiB,KAAK,SAAS,EAAE,CAAC;wBACpC,MAAM,IAAI,KAAK,CACb,qEAAqE,CACtE,CAAC;oBACJ,CAAC;oBAED,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,GAAG,EAAE,iBAAiB,CAAC,CAAC;oBAE9D,OAAO,IAAA,kDAAoC,EACzC,UAAU,EACV,UAAU,CAAC,cAAc,EACzB,iBAAiB,EACjB,MAAM,CACP,CAAC;gBACJ,CAAC,CACF,CAAC;QAEV,MAAM,MAAM,GAAG,MAAM,IAAA,eAAG,EACtB;YACE,IAAI,EAAE,MAAM;YACZ,IAAI,EAAE,KAAK,EAAE,GAAG,EAAE,EAAE,iBAAiB,EAAE,OAAO,EAAE,EAAE,EAAE,CAClD,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,kDAAkD,EAClD,EAAE,EACF,KAAK,IAAI,EAAE;gBACT,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,GAAG,EAAE,iBAAiB,CAAC,CAAC;gBAE9D,OAAO,IAAA,kDAAoC,EACzC,UAAU,EACV,OAAO,EACP,iBAAiB,EACjB,MAAM,CACP,CAAC;YACJ,CAAC,CACF;YACH,SAAS,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAE,EAAE,EAAE,CAC5C,IAAI,CAAC,SAAS,CAAC,EAAE,aAAa,EAAE,0BAAW,EAAE,EAAE,EAAE,OAAO,EAAE,iBAAiB,EAAE,CAAC;SACjF,EACD,UAAU,CAAC,OAAO,CAAC,kBAAkB,EACrC,UAAU,CAAC,OAAO,CAAC,WAAW,CAC/B,CAAC;QAEF,IAAI,UAAU,CAAC,OAAO,CAAC,UAAU,KAAK,SAAS,EAAE,CAAC;YAChD,MAAM,CAAC,UAAU,CAAC,UAAU,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;YACjD,UAAU,CAAC,OAAO,CAAC,UAAU,CAAC,MAAM,CAAC,iBAAiB,EAAE,CAAC,CAAC;QAC5D,CAAC;QAED,OAAO,MAAM,CAAC;IAChB,CAAC;CAGF;AAvxBD,wDAuxBC;AAED;;;GAGG;AACH,SAAS,gBAAgB,CACvB,KAAqB;IAIrB,QAAQ,KAAK,CAAC,IAAI,EAAE,CAAC;QACnB,KAAK,MAAM;YACT,OAAO,CAAC,0BAA0B,EAAE,KAAK,CAAC,IAAI,CAAC,CAAC;QAClD,KAAK,KAAK;YACR,OAAO,CAAC,kBAAkB,EAAE,EAAE,SAAS,EAAE,KAAK,CAAC,GAAG,EAAE,CAAC,CAAC;QACxD,KAAK,QAAQ;YACX,OAAO,CAAC,kBAAkB,EAAE,EAAE,YAAY,EAAE,KAAK,CAAC,MAAM,EAAE,CAAC,CAAC;QAC9D,OAAO,CAAC,CAAC,CAAC;YACR,MAAM,SAAS,GAAU,KAAK,CAAC;YAC/B,MAAM,IAAI,KAAK,CAAC,wCAAwC,SAAS,EAAE,CAAC,CAAC;QACvE,CAAC;IACH,CAAC;AACH,CAAC;AAED;;GAEG;AACH,uFAAuF;AAEvF,SAAS,MAAM,CACb,IAAO,EACP,KAA2F;IAE3F,OAAO;QACL,IAAI;QACJ,CAAC,IAAI,CAAC,EAAE,KAAK;KACe,CAAC;AACjC,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT License.\n\nimport type { KeyCredential, TokenCredential } from \"@azure/core-auth\";\nimport { createTracingClient } from \"@azure/core-tracing\";\nimport type { TracingClient } from \"@azure/core-tracing\";\nimport { FORM_RECOGNIZER_API_VERSION, SDK_VERSION } from \"./constants.js\";\nimport type {\n  AnalyzeDocumentRequest,\n  AnalyzeResultOperation,\n  GeneratedClient,\n} from \"./generated/index.js\";\nimport { accept1 } from \"./generated/models/parameters.js\";\nimport type {\n  AnalysisOperationDefinition,\n  AnalysisPoller,\n  AnalyzeResult,\n  DocumentAnalysisPollOperationState,\n  FormRecognizerRequestBody,\n} from \"./lro/analysis.js\";\nimport {\n  toAnalyzeResultFromGenerated,\n  toDocumentAnalysisPollOperationState,\n} from \"./lro/analysis.js\";\nimport type { OperationContext } from \"./lro/util/poller.js\";\nimport { lro } from \"./lro/util/poller.js\";\nimport type { AnalyzeDocumentOptions } from \"./options/AnalyzeDocumentOptions.js\";\nimport type { DocumentAnalysisClientOptions } from \"./options/FormRecognizerClientOptions.js\";\nimport type { DocumentModel } from \"./documentModel.js\";\nimport { makeServiceClient, Mappers, SERIALIZER } from \"./util.js\";\nimport type { AbortSignalLike } from \"@azure/abort-controller\";\nimport type { ClassifyDocumentOptions } from \"./options/ClassifyDocumentOptions.js\";\n\n/**\n * A client for interacting with the Form Recognizer service's analysis features.\n *\n * ### Examples:\n *\n * The Form Recognizer service and clients support two means of authentication:\n *\n * #### Azure Active Directory\n *\n * ```ts snippet:ReadmeSampleCreateClient_TokenCredential\n * import { DefaultAzureCredential } from \"@azure/identity\";\n * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n *\n * const credential = new DefaultAzureCredential();\n * const client = new DocumentAnalysisClient(\n *   \"https://<resource name>.cognitiveservices.azure.com\",\n *   credential,\n * );\n * ```\n *\n * #### API Key (Subscription Key)\n *\n * ```ts snippet:ReadmeSampleCreateClient_KeyCredential\n * import { AzureKeyCredential, DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n *\n * const credential = new AzureKeyCredential(\"<API key>\");\n * const client = new DocumentAnalysisClient(\n *   \"https://<resource name>.cognitiveservices.azure.com\",\n *   credential,\n * );\n * ```\n */\nexport class DocumentAnalysisClient {\n  private _restClient: GeneratedClient;\n  private _tracing: TracingClient;\n\n  /**\n   * Create a `DocumentAnalysisClient` instance from a resource endpoint and a an Azure Identity `TokenCredential`.\n   *\n   * See the [`@azure/identity`](https://npmjs.com/package/\\@azure/identity) package for more information about\n   * authenticating with Azure Active Directory.\n   *\n   * ### Example:\n   *\n   * ```ts snippet:ReadmeSampleCreateClient_TokenCredential\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   *\n   * const credential = new DefaultAzureCredential();\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   * ```\n   *\n   * @param endpoint - the endpoint URL of an Azure Cognitive Services instance\n   * @param credential - a TokenCredential instance from the `@azure/identity` package\n   * @param options - optional settings for configuring all methods in the client\n   */\n  public constructor(\n    endpoint: string,\n    credential: TokenCredential,\n    options?: DocumentAnalysisClientOptions,\n  );\n  /**\n   * Create a `DocumentAnalysisClient` instance from a resource endpoint and a static API key (`KeyCredential`),\n   *\n   * ### Example:\n   *\n   * ```ts snippet:ReadmeSampleCreateClient_KeyCredential\n   * import { AzureKeyCredential, DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   *\n   * const credential = new AzureKeyCredential(\"<API key>\");\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   * ```\n   *\n   * @param endpoint - the endpoint URL of an Azure Cognitive Services instance\n   * @param credential - a KeyCredential containing the Cognitive Services instance subscription key\n   * @param options - optional settings for configuring all methods in the client\n   */\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential,\n    options?: DocumentAnalysisClientOptions,\n  );\n  /**\n   * @hidden\n   */\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential | TokenCredential,\n    options?: DocumentAnalysisClientOptions,\n  );\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential | TokenCredential,\n    options: DocumentAnalysisClientOptions = {},\n  ) {\n    this._restClient = makeServiceClient(endpoint, credential, options);\n    this._tracing = createTracingClient({\n      packageName: \"@azure/ai-form-recognizer\",\n      packageVersion: SDK_VERSION,\n      namespace: \"Microsoft.CognitiveServices\",\n    });\n  }\n\n  // #region Analysis\n\n  /**\n   * Extract data from an input using a model given by its unique ID.\n   *\n   * This operation supports custom as well as prebuilt models. For example, to use the prebuilt invoice model, provide\n   * the model ID \"prebuilt-invoice\", or to use the simpler prebuilt layout model, provide the model ID\n   * \"prebuilt-layout\".\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis, and the values in any\n   * extracted documents' fields depend on the document types in the model (if any) and their corresponding field\n   * schemas.\n   *\n   * ### Examples\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * ```ts snippet:ReadmeSamplePrebuiltReceipt\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   * import { createReadStream } from \"node:fs\";\n   * import { PrebuiltReceiptModel } from \"../samples-dev/prebuilt/prebuilt-receipt.js\";\n   *\n   * const credential = new DefaultAzureCredential();\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   *\n   * const path = \"<path to a document>\";\n   * const readStream = createReadStream(path);\n   *\n   * // The PrebuiltReceiptModel `DocumentModel` instance encodes both the model ID and a stronger return type for the operation\n   * const poller = await client.beginAnalyzeDocument(PrebuiltReceiptModel, readStream, {\n   *   onProgress: ({ status }) => {\n   *     console.log(`status: ${status}`);\n   *   },\n   * });\n   *\n   * const {\n   *   documents: [receiptDocument],\n   * } = await poller.pollUntilDone();\n   *\n   * // The fields of the document constitute the extracted receipt data.\n   * const receipt = receiptDocument.fields;\n   *\n   * if (receipt === undefined) {\n   *   throw new Error(\"Expected at least one receipt in analysis result.\");\n   * }\n   *\n   * console.log(`Receipt data (${receiptDocument.docType})`);\n   * console.log(\"  Merchant Name:\", receipt.merchantName?.value);\n   *\n   * // The items of the receipt are an example of a `DocumentArrayValue`\n   * if (receipt.items !== undefined) {\n   *   console.log(\"Items:\");\n   *   for (const { properties: item } of receipt.items.values) {\n   *     console.log(\"- Description:\", item.description?.value);\n   *     console.log(\"  Total Price:\", item.totalPrice?.value);\n   *   }\n   * }\n   *\n   * console.log(\"  Total:\", receipt.total?.value);\n   * ```\n   *\n   *\n   * @param modelId - the unique ID (name) of the model within this client's resource\n   * @param document - a {@link FormRecognizerRequestBody} that will be uploaded with the request\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocument(\n    modelId: string,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions,\n  ): Promise<AnalysisPoller>;\n  /**\n   * Extract data from an input using a model that has a known, strongly-typed document schema (a {@link DocumentModel}).\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis. In TypeScript, the type\n   * of the result for this method overload is inferred from the type of the input `DocumentModel`.\n   *\n   * ### Examples\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * If the input provided is a string, it will be treated as a URL to the location of a document to be analyzed. See the\n   * {@link beginAnalyzeDocumentFromUrl} method for more information. Use of that method is preferred when using URLs,\n   * and URL support is only provided in this method for backwards compatibility.\n   *\n   * ```ts snippet:ReadmeSamplePrebuiltReceipt\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   * import { createReadStream } from \"node:fs\";\n   * import { PrebuiltReceiptModel } from \"../samples-dev/prebuilt/prebuilt-receipt.js\";\n   *\n   * const credential = new DefaultAzureCredential();\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   *\n   * const path = \"<path to a document>\";\n   * const readStream = createReadStream(path);\n   *\n   * // The PrebuiltReceiptModel `DocumentModel` instance encodes both the model ID and a stronger return type for the operation\n   * const poller = await client.beginAnalyzeDocument(PrebuiltReceiptModel, readStream, {\n   *   onProgress: ({ status }) => {\n   *     console.log(`status: ${status}`);\n   *   },\n   * });\n   *\n   * const {\n   *   documents: [receiptDocument],\n   * } = await poller.pollUntilDone();\n   *\n   * // The fields of the document constitute the extracted receipt data.\n   * const receipt = receiptDocument.fields;\n   *\n   * if (receipt === undefined) {\n   *   throw new Error(\"Expected at least one receipt in analysis result.\");\n   * }\n   *\n   * console.log(`Receipt data (${receiptDocument.docType})`);\n   * console.log(\"  Merchant Name:\", receipt.merchantName?.value);\n   *\n   * // The items of the receipt are an example of a `DocumentArrayValue`\n   * if (receipt.items !== undefined) {\n   *   console.log(\"Items:\");\n   *   for (const { properties: item } of receipt.items.values) {\n   *     console.log(\"- Description:\", item.description?.value);\n   *     console.log(\"  Total Price:\", item.totalPrice?.value);\n   *   }\n   * }\n   *\n   * console.log(\"  Total:\", receipt.total?.value);\n   * ```\n   *\n   * @param model - a {@link DocumentModel} representing the model to use for analysis and the expected output type\n   * @param document - a {@link FormRecognizerRequestBody} that will be uploaded with the request\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult` with documents that have\n   *          the result type associated with the input model\n   */\n  public async beginAnalyzeDocument<Result>(\n    model: DocumentModel<Result>,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions<Result>,\n  ): Promise<AnalysisPoller<Result>>;\n  public async beginAnalyzeDocument(\n    model: string | DocumentModel<unknown>,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options: AnalyzeDocumentOptions<unknown> = {},\n  ): Promise<AnalysisPoller<unknown>> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginAnalyzeDocument\",\n      options,\n      // In the first version of the SDK, the document input was treated as a URL if it was a string, and we preserve\n      // this behavior to avoid introducing a breaking change.\n      this.analyze.bind(\n        this,\n        model,\n        typeof document === \"string\" ? source(\"url\", document) : source(\"body\", document),\n      ),\n    );\n  }\n\n  /**\n   * Extract data from an input using a model given by its unique ID.\n   *\n   * This operation supports custom as well as prebuilt models. For example, to use the prebuilt invoice model, provide\n   * the model ID \"prebuilt-invoice\", or to use the simpler prebuilt layout model, provide the model ID\n   * \"prebuilt-layout\".\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis, and the values in any\n   * extracted documents' fields depend on the document types in the model (if any) and their corresponding field\n   * schemas.\n   *\n   * ### Examples\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```ts snippet:ReadmeSampleReceiptModelID_URL\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   * import {\n   *   DocumentAnalysisClient,\n   *   DocumentStringField,\n   *   DocumentArrayField,\n   *   DocumentObjectField,\n   * } from \"@azure/ai-form-recognizer\";\n   *\n   * const credential = new DefaultAzureCredential();\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   *\n   * const poller = await client.beginAnalyzeDocumentFromUrl(\n   *   \"prebuilt-receipt\",\n   *   // The Document Intelligence service will access the following URL to a receipt image and extract data from it\n   *   \"https://raw.githubusercontent.com/Azure/azure-sdk-for-js/main/sdk/formrecognizer/ai-form-recognizer/assets/receipt/contoso-receipt.png\",\n   * );\n   * poller.onProgress((state) => console.log(\"Operation:\", state.modelId, state.status));\n   *\n   * const { documents } = await poller.pollUntilDone();\n   *\n   * const result = documents && documents[0];\n   * if (result) {\n   *   const receipt = result.fields;\n   *   console.log(\"=== Receipt Information ===\");\n   *   console.log(\"Type:\", result.docType);\n   *   console.log(\"Merchant:\", (receipt[\"MerchantName\"] as DocumentStringField).value);\n   *\n   *   console.log(\"Items:\");\n   *   for (const { properties: item } of ((receipt[\"Items\"] as DocumentArrayField).values ||\n   *     []) as DocumentObjectField[]) {\n   *     console.log(\"- Description:\", (item[\"Description\"] as DocumentStringField).value);\n   *     console.log(\"  Total Price:\", (item[\"TotalPrice\"] as DocumentStringField).value);\n   *   }\n   * } else {\n   *   throw new Error(\"Expected at least one receipt in the result.\");\n   * }\n   * ```\n   *\n   * @param modelId - the unique ID (name) of the model within this client's resource\n   * @param documentUrl - a URL (string) to an input document accessible from the public internet\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocumentFromUrl(\n    modelId: string,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions,\n  ): Promise<AnalysisPoller>;\n  /**\n   * Extract data from an input using a model that has a known, strongly-typed document schema (a {@link DocumentModel}).\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis. In TypeScript, the type\n   * of the result for this method overload is inferred from the type of the input `DocumentModel`.\n   *\n   * ### Examples\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```ts snippet:ReadmeSampleReceiptPrebuilt_URL\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   * import { PrebuiltReceiptModel } from \"../samples-dev/prebuilt/prebuilt-receipt.js\";\n   *\n   * const credential = new DefaultAzureCredential();\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   *\n   * const poller = await client.beginAnalyzeDocumentFromUrl(\n   *   PrebuiltReceiptModel,\n   *   // The Document Intelligence service will access the following URL to a receipt image and extract data from it\n   *   \"https://raw.githubusercontent.com/Azure/azure-sdk-for-js/main/sdk/formrecognizer/ai-form-recognizer/assets/receipt/contoso-receipt.png\",\n   * );\n   *\n   * const {\n   *   documents: [document],\n   * } = await poller.pollUntilDone();\n   *\n   * // Use of PrebuiltModels.Receipt above (rather than the raw model ID), as it adds strong typing of the model's output\n   * if (document) {\n   *   const { merchantName, items, total } = document.fields;\n   *\n   *   console.log(\"=== Receipt Information ===\");\n   *   console.log(\"Type:\", document.docType);\n   *   console.log(\"Merchant:\", merchantName && merchantName.value);\n   *\n   *   console.log(\"Items:\");\n   *   for (const item of (items && items.values) || []) {\n   *     const { description, totalPrice } = item.properties;\n   *\n   *     console.log(\"- Description:\", description && description.value);\n   *     console.log(\"  Total Price:\", totalPrice && totalPrice.value);\n   *   }\n   *\n   *   console.log(\"Total:\", total && total.value);\n   * } else {\n   *   throw new Error(\"Expected at least one receipt in the result.\");\n   * }\n   * ```\n   *\n   * @param model - a {@link DocumentModel} representing the model to use for analysis and the expected output type\n   * @param documentUrl - a URL (string) to an input document accessible from the public internet\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocumentFromUrl<Result>(\n    model: DocumentModel<Result>,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions<Result>,\n  ): Promise<AnalysisPoller<Result>>;\n  public async beginAnalyzeDocumentFromUrl(\n    model: string | DocumentModel<unknown>,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options: AnalyzeDocumentOptions<unknown> = {},\n  ): Promise<AnalysisPoller<unknown>> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginAnalyzeDocumentFromUrl\",\n      options,\n      this.analyze.bind(this, model, source(\"url\", documentUrl)),\n    );\n  }\n\n  /**\n   * A helper method for running analysis polymorphically.\n   *\n   * @param model - the model ID or DocumentModel to use for analysis\n   * @param input - the string URL or request body to use\n   * @param options - analysis options\n   * @returns - an analysis poller\n   */\n  private analyze(\n    model: string | DocumentModel<unknown>,\n    input: DocumentSource,\n    options: AnalyzeDocumentOptions<unknown>,\n  ): Promise<AnalysisPoller<unknown>> {\n    const {\n      modelId: initialModelId,\n      apiVersion: requestApiVersion,\n      transformResult,\n    } = typeof model === \"string\"\n      ? { modelId: model, apiVersion: undefined, transformResult: (v: AnalyzeResult) => v }\n      : model;\n\n    if (requestApiVersion && requestApiVersion !== FORM_RECOGNIZER_API_VERSION) {\n      throw new Error(\n        [\n          `API Version mismatch: the provided model wants version: ${requestApiVersion},`,\n          `but the client is using ${FORM_RECOGNIZER_API_VERSION}.`,\n          \"The API version of the model must match the client's API version.\",\n        ].join(\" \"),\n      );\n    }\n\n    return this.createUnifiedPoller<unknown>(\n      (abortSignal) => {\n        const [contentType, analyzeRequest] = toAnalyzeRequest(input);\n\n        if (contentType === \"application/json\") {\n          return this._restClient.documentModels.analyzeDocument(initialModelId, contentType, {\n            ...options,\n            abortSignal,\n            analyzeRequest,\n          });\n        } else {\n          return this._restClient.documentModels.analyzeDocument(initialModelId, contentType, {\n            ...options,\n            abortSignal,\n            analyzeRequest,\n          });\n        }\n      },\n      {\n        initialModelId,\n        options,\n        transformResult: (result) => transformResult(toAnalyzeResultFromGenerated(result)),\n      },\n    );\n  }\n\n  /**\n   * Classify a document using a custom classifier given by its ID.\n   *\n   * This method produces a long-running operation (poller) that will eventually produce an `AnalyzeResult`. This is the\n   * same type as `beginAnalyzeDocument` and `beginAnalyzeDocumentFromUrl`, but the result will only contain a small\n   * subset of its fields. Only the `documents` field and `pages` field will be populated, and only minimal page\n   * information will be returned. The `documents` field will contain information about all the identified documents and\n   * the `docType` that they were classified as.\n   *\n   * ### Example\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * ```ts snippet:ReadmeSampleClassifyDocument_File\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   * import { createReadStream } from \"node:fs\";\n   *\n   * const credential = new DefaultAzureCredential();\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   *\n   * const path = \"<path to a document>\";\n   * const readStream = createReadStream(path);\n   *\n   * const poller = await client.beginClassifyDocument(\"<classifier id>\", readStream);\n   *\n   * const result = await poller.pollUntilDone();\n   *\n   * if (result?.documents?.length === 0) {\n   *   throw new Error(\"Failed to extract any documents.\");\n   * }\n   *\n   * for (const document of result.documents) {\n   *   console.log(\n   *     `Extracted a document with type '${document.docType}' on page ${document.boundingRegions?.[0].pageNumber} (confidence: ${document.confidence})`,\n   *   );\n   * }\n   * ```\n   *\n   * @param classifierId - the ID of the custom classifier to use for analysis\n   * @param document - the document to classify\n   * @param options - options for the classification operation\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginClassifyDocument(\n    classifierId: string,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options: ClassifyDocumentOptions = {},\n  ): Promise<AnalysisPoller> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginClassifyDocument\",\n      options,\n      this.classify.bind(this, classifierId, source(\"body\", document)),\n    );\n  }\n\n  /**\n   * Classify a document from a URL using a custom classifier given by its ID.\n   *\n   * This method produces a long-running operation (poller) that will eventually produce an `AnalyzeResult`. This is the\n   * same type as `beginAnalyzeDocument` and `beginAnalyzeDocumentFromUrl`, but the result will only contain a small\n   * subset of its fields. Only the `documents` field and `pages` field will be populated, and only minimal page\n   * information will be returned. The `documents` field will contain information about all the identified documents and\n   * the `docType` that they were classified as.\n   *\n   * ### Example\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```ts snippet:ReadmeSampleClassifyDocument\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   *\n   * const credential = new DefaultAzureCredential();\n   * const client = new DocumentAnalysisClient(\n   *   \"https://<resource name>.cognitiveservices.azure.com\",\n   *   credential,\n   * );\n   *\n   * const documentUrl =\n   *   \"https://raw.githubusercontent.com/Azure/azure-sdk-for-js/main/sdk/formrecognizer/ai-form-recognizer/assets/invoice/Invoice_1.pdf\";\n   *\n   * const poller = await client.beginClassifyDocumentFromUrl(\"<classifier id>\", documentUrl);\n   *\n   * const result = await poller.pollUntilDone();\n   *\n   * if (result?.documents?.length === 0) {\n   *   throw new Error(\"Failed to extract any documents.\");\n   * }\n   *\n   * for (const document of result.documents) {\n   *   console.log(\n   *     `Extracted a document with type '${document.docType}' on page ${document.boundingRegions?.[0].pageNumber} (confidence: ${document.confidence})`,\n   *   );\n   * }\n   * ```\n   * @param classifierId - the ID of the custom classifier to use for analysis\n   * @param documentUrl - the URL of the document to classify\n   * @param options -\n   * @returns\n   */\n  public async beginClassifyDocumentFromUrl(\n    classifierId: string,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options: ClassifyDocumentOptions = {},\n  ): Promise<AnalysisPoller> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginClassifyDocumentFromUrl\",\n      options,\n      this.classify.bind(this, classifierId, source(\"url\", documentUrl)),\n    );\n  }\n\n  /**\n   * A helper method for running classification polymorphically.\n   * @param classifierId - the ID of the classifier to use\n   * @param input - the string URL or request body to use\n   * @param options - analysis options\n   * @returns an analysis poller\n   */\n  private classify(\n    classifierId: string,\n    input: DocumentSource,\n    options: ClassifyDocumentOptions,\n  ): Promise<AnalysisPoller> {\n    return this.createUnifiedPoller(\n      async (abortSignal) => {\n        const [contentType, classifyRequest] = toAnalyzeRequest(input);\n\n        if (contentType === \"application/json\") {\n          return this._restClient.documentClassifiers.classifyDocument(\n            classifierId,\n            contentType as any,\n            {\n              ...options,\n              abortSignal,\n              classifyRequest,\n            },\n          );\n        } else {\n          return this._restClient.documentClassifiers.classifyDocument(\n            classifierId,\n            contentType as any,\n            {\n              ...options,\n              abortSignal,\n              classifyRequest,\n            },\n          );\n        }\n      },\n      {\n        initialModelId: classifierId,\n        options,\n        transformResult: toAnalyzeResultFromGenerated,\n      },\n    );\n  }\n\n  /**\n   * Create an LRO poller that handles analysis operations.\n   *\n   * This is the meat of all analysis polling operations.\n   *\n   * @param startOperation - function that starts the operation and returns the operation location\n   * @param definition - operation definition (initial model ID, operation transforms, request options)\n   * @returns - an analysis poller that produces the given return types according to the operation spec\n   */\n  private async createUnifiedPoller<Result>(\n    startOperation: (\n      abortSignal: AbortSignalLike | undefined,\n    ) => Promise<{ operationLocation?: string }>,\n    definition: AnalysisOperationDefinition<Result>,\n  ): Promise<AnalysisPoller<Result>> {\n    const { resumeFrom } = definition.options;\n\n    // TODO: what should we do if resumeFrom.modelId is different from initialModelId?\n    // And what do we do with the redundant input??\n\n    const getAnalyzeResult = (\n      ctx: OperationContext,\n      operationLocation: string,\n    ): Promise<AnalyzeResultOperation> =>\n      this._tracing.withSpan(\n        \"DocumentAnalysisClient.createAnalysisPoller-getAnalyzeResult\",\n        definition.options,\n        (finalOptions) =>\n          this._restClient.sendOperationRequest<AnalyzeResultOperation>(\n            {\n              options: {\n                onResponse: async (rawResponse, ...args) => {\n                  // Capture the `Retry-After` header if it was sent.\n                  const retryAfterHeader = rawResponse.headers.get(\"retry-after\");\n                  // Convert the header value to milliseconds. If the header is not a valid number, then it is an HTTP\n                  // date.\n                  if (retryAfterHeader) {\n                    const retryAfterMs = Number(retryAfterHeader) * 1000;\n                    if (!Number.isNaN(retryAfterMs)) {\n                      ctx.updateDelay(retryAfterMs);\n                    } else {\n                      ctx.updateDelay(Date.parse(retryAfterHeader) - Date.now());\n                    }\n                  } else {\n                    ctx.updateDelay(undefined);\n                  }\n\n                  // Forward the `onResponse` callback if it was provided.\n                  return finalOptions.onResponse?.(rawResponse, ...args);\n                },\n                ...finalOptions,\n                // We need to pass the abort signal from the context rather than from the options, since the user could\n                // poll the LRO with a different AbortSignal than it was instantiated with.\n                abortSignal: ctx.abortSignal,\n              },\n            },\n            {\n              path: operationLocation,\n              httpMethod: \"GET\",\n              responses: {\n                200: {\n                  bodyMapper: Mappers.AnalyzeResultOperation,\n                },\n                default: {\n                  bodyMapper: Mappers.ErrorResponse,\n                },\n              },\n              // URL is fully-formed, so we don't need any query parameters\n              headerParameters: [accept1],\n              serializer: SERIALIZER,\n            },\n          ),\n      );\n\n    const toInit =\n      // If the user gave us a stored token, we'll poll it again\n      resumeFrom !== undefined\n        ? async (ctx: OperationContext) =>\n            this._tracing.withSpan(\n              \"DocumentAnalysisClient.createAnalysisPoller-resume\",\n              definition.options,\n              async () => {\n                const { clientVersion, operationLocation, modelId } = JSON.parse(resumeFrom) as {\n                  clientVersion?: string;\n                  operationLocation: string;\n                  modelId: string;\n                };\n\n                if (!clientVersion || clientVersion !== SDK_VERSION) {\n                  throw new Error(\n                    [\n                      \"Cannot restore poller from a serialized state from a different version of the client\",\n                      `library (restoreFrom: '${clientVersion}', current: '${SDK_VERSION}').`,\n                    ].join(\" \"),\n                  );\n                }\n\n                const result = await getAnalyzeResult(ctx, operationLocation);\n\n                return toDocumentAnalysisPollOperationState(\n                  definition,\n                  modelId,\n                  operationLocation,\n                  result,\n                );\n              },\n            )\n        : // Otherwise, we'll start a new operation from the initialModelId\n          async (ctx: OperationContext) =>\n            this._tracing.withSpan(\n              \"DocumentAnalysisClient.createAnalysisPoller-start\",\n              definition.options,\n              async () => {\n                const { operationLocation } = await startOperation(ctx.abortSignal);\n\n                if (operationLocation === undefined) {\n                  throw new Error(\n                    \"Unable to start analysis operation: no Operation-Location received.\",\n                  );\n                }\n\n                const result = await getAnalyzeResult(ctx, operationLocation);\n\n                return toDocumentAnalysisPollOperationState(\n                  definition,\n                  definition.initialModelId,\n                  operationLocation,\n                  result,\n                );\n              },\n            );\n\n    const poller = await lro<Result, DocumentAnalysisPollOperationState<Result>>(\n      {\n        init: toInit,\n        poll: async (ctx, { operationLocation, modelId }) =>\n          this._tracing.withSpan(\n            \"DocumentAnalysisClient.createAnalysisPoller-poll\",\n            {},\n            async () => {\n              const result = await getAnalyzeResult(ctx, operationLocation);\n\n              return toDocumentAnalysisPollOperationState(\n                definition,\n                modelId,\n                operationLocation,\n                result,\n              );\n            },\n          ),\n        serialize: ({ operationLocation, modelId }) =>\n          JSON.stringify({ clientVersion: SDK_VERSION, id: modelId, operationLocation }),\n      },\n      definition.options.updateIntervalInMs,\n      definition.options.abortSignal,\n    );\n\n    if (definition.options.onProgress !== undefined) {\n      poller.onProgress(definition.options.onProgress);\n      definition.options.onProgress(poller.getOperationState());\n    }\n\n    return poller;\n  }\n\n  // #endregion\n}\n\n/**\n * Produce an appropriate pair of content-type and analyzeRequest value for the analysis request.\n * @internal\n */\nfunction toAnalyzeRequest(\n  input: DocumentSource,\n):\n  | [\"application/json\", AnalyzeDocumentRequest]\n  | [\"application/octet-stream\", FormRecognizerRequestBody] {\n  switch (input.kind) {\n    case \"body\":\n      return [\"application/octet-stream\", input.body];\n    case \"url\":\n      return [\"application/json\", { urlSource: input.url }];\n    case \"base64\":\n      return [\"application/json\", { base64Source: input.base64 }];\n    default: {\n      const __exhaust: never = input;\n      throw new Error(`Unreachable 'toAnalyzeRequest' case: ${__exhaust}`);\n    }\n  }\n}\n\n/**\n * The input to a document analysis operation.\n */\n// type DocumentSource = DocumentBodySource | DocumentUrlSource | DocumentBase64Source;\n\nfunction source<K extends DocumentSource[\"kind\"]>(\n  kind: K,\n  value: Extract<DocumentSource, { kind: K }>[K & keyof Extract<DocumentSource, { kind: K }>],\n): DocumentSource {\n  return {\n    kind,\n    [kind]: value,\n  } as unknown as DocumentSource;\n}\n\n/**\n * The input to a document analysis operation.\n *\n * @internal\n */\ntype DocumentSource = {\n  [K in keyof DocumentSourceTypes]: {\n    /** The input kind. */\n    kind: K;\n  } & { [_ in K]: DocumentSourceTypes[K] };\n}[keyof DocumentSourceTypes];\n\n/**\n * A map of input discriminants to concrete input types.\n *\n * @internal\n */\ninterface DocumentSourceTypes {\n  /**\n   * A document buffer or stream to be uploaded in the request body.\n   */\n  body: FormRecognizerRequestBody;\n\n  /**\n   * A URL to a document to be analyzed.\n   */\n  url: string;\n\n  /**\n   * The data of a document to be analyzed. This is NOT base64-encoded, but will\n   * be base64-encoded by the client before uploading.\n   *\n   * NOTE: This is never used by the client because it is inefficient compared to direct uploads and does not currently\n   * support any features that `body` does not.\n   */\n  base64: Uint8Array;\n}\n"]}